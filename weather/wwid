import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 1. Load your dataset
# df = pd.read_csv('your_data.csv')

# 2. Define the Gini Index (based on AUC)
def gini_index(y_true, y_pred):
    auc = roc_auc_score(y_true, y_pred)
    gini = 2 * auc - 1
    return gini

# 3. Define the logistic regression stepwise function
def stepwise_logistic_regression(df, target, exclude_vars, max_gini_increase=0.01):
    """
    Performs stepwise logistic regression to select features that increase the Gini index
    by more than a threshold (default 1%).
    
    Args:
        df (DataFrame): The dataset.
        target (str): The name of the target variable.
        exclude_vars (list): List of variables to exclude from being potential regressors.
        max_gini_increase (float): The maximum allowable Gini increase for a new variable to be added.

    Returns:
        selected_features (list): List of selected features for the logistic regression model.
    """
    # Step 1: Define initial variables
    features = [col for col in df.columns if col != target and col not in exclude_vars]
    selected_features = []
    
    # Step 2: Split data into train/test
    X = df[features]
    y = df[target]
    
    # Optionally scale the features if needed
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Step 3: Initial Gini index (without any feature)
    model = LogisticRegression()
    model.fit(X_scaled, y)
    y_pred = model.predict_proba(X_scaled)[:, 1]
    initial_gini = gini_index(y, y_pred)
    
    print(f"Initial Gini: {initial_gini}")
    
    # Step 4: Stepwise process to add features
    remaining_features = [f for f in features if f not in selected_features]
    last_gini = initial_gini
    
    while remaining_features:
        best_gini_increase = -np.inf
        best_feature = None
        
        for feature in remaining_features:
            # Add one feature at a time
            selected_features.append(feature)
            X_new = df[selected_features]
            X_scaled = scaler.fit_transform(X_new)
            
            model.fit(X_scaled, y)
            y_pred = model.predict_proba(X_scaled)[:, 1]
            new_gini = gini_index(y, y_pred)
            
            gini_increase = new_gini - last_gini
            print(f"Trying feature: {feature} | Gini increase: {gini_increase}")
            
            # Check if the Gini index improved enough
            if gini_increase > best_gini_increase:
                best_gini_increase = gini_increase
                best_feature = feature
            
            # Remove the feature from the selected features list after testing
            selected_features.remove(feature)
        
        # If we found a feature that improves Gini by more than the threshold, keep it
        if best_gini_increase > max_gini_increase:
            selected_features.append(best_feature)
            remaining_features.remove(best_feature)
            last_gini = last_gini + best_gini_increase
            print(f"Added feature: {best_feature} | New Gini: {last_gini}")
        else:
            break  # Stop if no feature improves the Gini by more than the threshold
    
    return selected_features

# Example usage:

# Assuming 'df' is the DataFrame and 'target' is the column with the default flag
# Set the list of variables you want to exclude from being used as regressors
exclude_vars = ['excluded_var_1', 'excluded_var_2', 'excluded_var_3']  # Example excluded variables
target = 'default_flag'  # Example target variable

# Run the stepwise logistic regression
selected_features = stepwise_logistic_regression(df, target, exclude_vars)

print(f"Selected features: {selected_features}")
