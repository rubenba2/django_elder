from scipy.stats import binom_test

# Step 1: Total number of observations
n = cohort_data.shape[0]

# Step 2: Total number of observed defaults
observed_defaults = cohort_data['def_flag'].sum()

# Step 3: Total expected defaults from predicted PDs
expected_defaults = cohort_data['proposed_final_pd'].sum()

# Step 4: Convert expected defaults to expected default rate
expected_default_rate = expected_defaults / n

# Step 5: Perform the binomial test
p_value = binom_test(observed_defaults, n, expected_default_rate, alternative='two-sided')

print(f"Observed Defaults: {observed_defaults}")
print(f"Expected Defaults (Sum of PDs): {expected_defaults:.2f}")
print(f"Expected Default Rate: {expected_default_rate:.4f}")
print(f"Binomial Test p-value: {p_value:.4f}")

# Optional interpretation
if p_value < 0.05:
    print("Result: Statistically significant difference — model may be miscalibrated.")
else:
    print("Result: No significant difference — model is calibrated to observed outcomes.")
